{
  "daemon": true,
  "run": [{
    "method": "shell.run",
    "params": {
      "path": "llama.cpp/build/bin",
      "message": "{{platform === 'win32' ? 'Release\\\\server.exe' : './server'}} -m ../../models/ggml-model-q4_k.gguf --mmproj ../../models/mmproj-model-f16.gguf -ngl 1",
      "on": [{
        "event": "/llama server listening at (http:\/\/[0-9:])/i",
        "done": true
      }]
    }
  }, {
    "method": "self.set",
    "params": { "session.json": { "url": "{{input.event[1]}}" } }
  }, {
    "method": "shell.run",
    "params": {
      "venv": "bakllava-venv",
      "path": "realtime-bakllava",
      "message": "python src/video_stream.py"
    }
  }]
}
